const researchPapers = {
    "foundational_papers": [
      {
        title: "A Mathematical Theory of Communication",
        url: "https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf"
      },
      {
        title: "A Logical Calculus of the Ideas Immanent in Nervous Activity",
        url: "https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf"
      },
      {
        title: "Intelligent Machinery",
        url: "https://ia801703.us.archive.org/23/items/turing1948/turing1948_text.pdf"
      },
      {
        title: "Programming a Computer for Playing Chess",
        url: "https://archive.computerhistory.org/projects/chess/related_materials/text/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon.062303002.pdf"
      },
      {
        title: "Perceptron",
        url: "https://bpb-us-e2.wpmucdn.com/websites.umass.edu/dist/a/27637/files/2016/03/rosenblatt-1957.pdf"
      },
      {
        title: "A Symbolic Analysis of Relay and Switching Circuits",
        url: "https://drive.google.com/file/d/1m3JwmCZqWg1IP607I5gbpsJDQBIDwcz9/view"
      }
    ],
    "neural_networks_and_deep_learning": [
      {
        title: "Learning representations by back-propagating errors",
        url: "https://github.com/georgezoto/Convolutional-Neural-Networks/blob/master/Papers/1986%20Backpro%20Learning%20representations%20by%20back-propagating%20errors%20-%20Rumelhart,%20Hinton,%20Williams.pdf"
      },
      {
        title: "Gradient-based learning applied to document recognition",
        url: "https://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"
      },
      {
        title: "The Annotated Transformer",
        url: "https://nlp.seas.harvard.edu/annotated-transformer/"
      },
      {
        title: "ImageNet Classification with Deep CNNs",
        url: "https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
      },
      {
        title: "CS231n Convolutional Neural Networks for Visual Recognition",
        url: "https://cs231n.github.io/"
      },
      {
        title: "Deep Residual Learning for Image Recognition",
        url: "https://arxiv.org/pdf/1512.03385"
      },
      {
        title: "Identity Mappings in Deep Residual Networks",
        url: "https://arxiv.org/pdf/1603.05027"
      },
      {
        title: "Multi-Scale Context Aggregation by Dilated Convolutions",
        url: "https://arxiv.org/pdf/1511.07122"
      }
    ],
    "language_models_and_nlp": [
      {
        title: "Attention Is All You Need",
        url: "https://arxiv.org/pdf/1706.03762"
      },
      {
        title: "Neural Networks and Neural Language Models",
        url: "https://web.stanford.edu/~jurafsky/slp3/7.pdf"
      },
      {
        title: "A Neural Probabilistic Language Model",
        url: "https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
      },
      {
        title: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        url: "https://arxiv.org/pdf/1810.04805"
      },
      {
        title: "The Llama 3 Herd of Models",
        url: "https://arxiv.org/pdf/2407.21783"
      },
      {
        title: "Scaling Laws for Neural LMs",
        url: "https://arxiv.org/pdf/2001.08361"
      }
    ],
    "sequence_models": [
      {
        title: "The Unreasonable Effectiveness of RNNs",
        url: "https://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      },
      {
        title: "Understanding LSTM Networks",
        url: "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      },
      {
        title: "Sequence to Sequence Learning with Neural Networks",
        url: "https://arxiv.org/pdf/1409.3215"
      },
      {
        title: "Neural Machine Translation by Jointly Learning to Align and Translate",
        url: "https://arxiv.org/pdf/1409.0473"
      },
      {
        title: "Generating Sequences With Recurrent Neural Networks",
        url: "https://arxiv.org/pdf/1308.0850"
      },
      {
        title: "Recurrent Neural Network Regularization",
        url: "https://arxiv.org/pdf/1409.2329"
      },
      {
        title: "Order Matters: Sequence to sequence for sets",
        url: "https://arxiv.org/pdf/1511.06391"
      },
      {
        title: "Pointer Networks",
        url: "https://arxiv.org/pdf/1506.03134"
      },
      {
        title: "Relational RNNs",
        url: "https://arxiv.org/pdf/1806.01822"
      }
    ],
    "machine_learning_theory": [
      {
        title: "Random Forests",
        url: "https://link.springer.com/content/pdf/10.1023/a:1010933404324.pdf"
      },
      {
        title: "Statistical Modeling: The Two Cultures",
        url: "https://www2.math.uu.se/~thulin/mm/breiman.pdf"
      },
      {
        title: "A Tutorial on Principal Component Analysis",
        url: "https://arxiv.org/pdf/1404.1100"
      },
      {
        title: "An overview of gradient descent optimization algorithms",
        url: "https://arxiv.org/pdf/1609.04747"
      },
      {
        title: "Keeping Neural Networks Simple by Minimizing the Description Length of the Weights",
        url: "https://www.cs.toronto.edu/~hinton/absps/colt93.pdf"
      },
      {
        title: "A Tutorial Introduction to the Minimum Description Length Principle",
        url: "https://arxiv.org/pdf/math/0406077"
      },
      {
        title: "Machine Super Intelligence",
        url: "http://www.vetta.org/documents/Machine_Super_Intelligence.pdf"
      },
      {
        title: "Kolmogorov Complexity and Algorithmic Randomness",
        url: "https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf"
      }
    ],
    "memory_and_attention": [
      {
        title: "Memory Networks",
        url: "https://arxiv.org/pdf/1410.3916"
      },
      {
        title: "Neural Turing Machines",
        url: "https://arxiv.org/pdf/1410.5401"
      },
      {
        title: "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
        url: "https://arxiv.org/pdf/2305.10250"
      },
      {
        title: "Effective Approaches to Attention-based Neural Machine Translation",
        url: "https://arxiv.org/pdf/1508.04025"
      }
    ],
    "specialized_applications": [
      {
        title: "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin",
        url: "https://arxiv.org/pdf/1512.02595"
      },
      {
        title: "Self-Driving Cars: A Survey",
        url: "https://arxiv.org/pdf/1901.04407"
      },
      {
        title: "Neural Quantum Chemistry",
        url: "https://arxiv.org/pdf/1704.01212"
      },
      {
        title: "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism",
        url: "https://arxiv.org/pdf/1811.06965"
      },
      {
        title: "A Simple NN Module for Relational Reasoning",
        url: "https://arxiv.org/pdf/1706.01427"
      }
    ],
    "technical_resources": [
      {
        title: "Papers in 100 Lines of Code",
        url: "https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code"
      },
      {
        title: "A Mathematical Framework for Transformer Circuits",
        url: "https://transformer-circuits.pub/2021/framework/index.html"
      },
      {
        title: "The NumPy array: a structure for efficient numerical computation",
        url: "https://arxiv.org/pdf/1102.1523"
      }
    ],
    "complexity_and_systems": [
      {
        title: "The First Law of Complexodynamics",
        url: "https://scottaaronson.blog/?p=762"
      },
      {
        title: "Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton",
        url: "https://arxiv.org/pdf/1405.6903"
      },
      {
        title: "Variational Lossy Autoencoder",
        url: "https://arxiv.org/pdf/1611.02731"
      }
    ]
  };

export default researchPapers;